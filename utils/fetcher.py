# utils/fetcher.py
import time
import random
from bs4 import BeautifulSoup
from playwright.sync_api import sync_playwright
import requests

# KhÃ´ng cáº§n User-Agent hay Session ná»¯a, Playwright sáº½ quáº£n lÃ½ táº¥t cáº£

def fetch_soup_playwright(url: str) -> BeautifulSoup:
    """
    Táº£i vÃ  parse HTML tá»« má»™t URL sá»­ dá»¥ng trÃ¬nh duyá»‡t khÃ´ng Ä‘áº§u Playwright.
    HÃ m nÃ y sáº½ thá»±c thi JavaScript vÃ  tráº£ vá» HTML cuá»‘i cÃ¹ng.
    """
    try:
        with sync_playwright() as p:
            # Sá»­ dá»¥ng trÃ¬nh duyá»‡t Chromium (giá»‘ng Chrome)
            browser = p.chromium.launch(headless=True) 
            page = browser.new_page()
            
            print(f"ğŸš€ Playwright Ä‘ang má»Ÿ trang: {url}")
            # Äi Ä‘áº¿n trang, chá» cho Ä‘áº¿n khi máº¡ng khÃ´ng cÃ²n hoáº¡t Ä‘á»™ng (tá»©c lÃ  Ä‘Ã£ táº£i xong)
            page.goto(url, wait_until="networkidle", timeout=30000)
            
            # Chá» thÃªm má»™t chÃºt Ä‘á»ƒ Ä‘áº£m báº£o cÃ¡c script cuá»‘i cÃ¹ng Ä‘Ã£ cháº¡y
            time.sleep(random.uniform(1, 2))
            
            # Láº¥y ná»™i dung HTML sau khi Ä‘Ã£ thá»±c thi JavaScript
            content = page.content()
            
            browser.close()
            
            return BeautifulSoup(content, "html.parser")

    except Exception as e:
        print(f"âŒ Lá»—i khi fetch báº±ng Playwright táº¡i URL {url}: {e}")
        return None

def get_full_headers():
    return {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',
        'Accept-Language': 'en-US,en;q=0.9,vi;q=0.8',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Fetch-Dest': 'document',
        'Sec-Fetch-Mode': 'navigate',
        'Sec-Fetch-Site': 'none',
        'Sec-Fetch-User': '?1',
        # Header Client Hints, ráº¥t quan trá»ng Ä‘á»ƒ trÃ´ng giá»‘ng Chrome tháº­t
        'Sec-CH-UA': '"Google Chrome";v="125", "Chromium";v="125", "Not.A/Brand";v="24"',
        'Sec-CH-UA-Mobile': '?0',
        'Sec-CH-UA-Platform': '"Windows"',
    }

# Báº¡n cÃ³ thá»ƒ giá»¯ láº¡i hÃ m fetch_soup cÅ© dÃ¹ng requests Ä‘á»ƒ dÃ¹ng cho cÃ¡c trang Ä‘Æ¡n giáº£n
# vÃ  chá»‰ gá»i fetch_soup_playwright cho cÃ¡c trang phá»©c táº¡p.

def fetch_soup(url: str) -> BeautifulSoup:
    """
    Táº£i vÃ  parse HTML tá»« má»™t URL sá»­ dá»¥ng requests.
    HÃ m nÃ y chá»‰ nÃªn Ä‘Æ°á»£c sá»­ dá»¥ng cho cÃ¡c trang web Ä‘Æ¡n giáº£n, khÃ´ng yÃªu cáº§u JavaScript.
    """
    try:
        session = requests.Session()
        response = session.get(url, headers=get_full_headers(), timeout=10)
        response.raise_for_status()  # Kiá»ƒm tra mÃ£ tráº¡ng thÃ¡i HTTP
        
        return BeautifulSoup(response.text, "html.parser")

    except Exception as e:
        print(f"âŒ Lá»—i khi fetch báº±ng requests táº¡i URL {url}: {e}")
        return None
