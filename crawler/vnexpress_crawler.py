import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from parsers.vnexpress_parser import parse_article
from database.db_manager import add_article

BASE_URL = "https://vnexpress.net"
TIN_NONG_URL = "https://vnexpress.net/tin-nong"

def get_article_links(limit: int = None) -> list:
    response = requests.get(TIN_NONG_URL, timeout=10)
    soup = BeautifulSoup(response.text, "html.parser")
    links = []

    for tag in soup.select("h3.title-news a[href]"):
        href = tag.get("href")
        if href.startswith("https://vnexpress.net") or href.startswith("/"):
            full_url = urljoin(BASE_URL, href)
            links.append(full_url)

    # Loáº¡i trÃ¹ng + giá»¯ thá»© tá»±
    seen = set()
    unique_links = []
    for link in links:
        if link not in seen:
            seen.add(link)
            unique_links.append(link)

    if limit is not None:
        return unique_links[:limit]

    return unique_links

def crawl_latest_articles(limit: int = None):
    print("ğŸš€ Äang crawl danh sÃ¡ch bÃ i viáº¿t tá»« má»¥c Tin NÃ³ng...")
    urls = get_article_links(limit=limit)
    print(f"ğŸ”— TÃ¬m Ä‘Æ°á»£c {len(urls)} bÃ i viáº¿t")

    new_count = 0
    for idx, url in enumerate(urls, start=1):
        print(f"ğŸ‘‰ ({idx}/{len(urls)}) {url}")
        article = parse_article(url)
        if not article:
            print("âŒ Lá»—i parse, bá» qua\n")
            continue

        # In ra URL áº£nh thumbnail (náº¿u cÃ³)
        thumb = article.get('thumbnail') or 'KhÃ´ng cÃ³'
        print(f"ğŸï¸ áº¢nh thumbnail: {thumb}")

        if article:
            if add_article(article):
                print(f"âœ… LÆ°u bÃ i má»›i: {article['title']}")
                new_count += 1
            else:
                print(f"â© ÄÃ£ tá»“n táº¡i: {article['title']}")

    print(f"\nğŸ‰ Tá»•ng sá»‘ bÃ i má»›i Ä‘Æ°á»£c lÆ°u: {new_count}")
