import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from utils.fetcher import fetch_soup
from parsers.vnexpress_parser import parse_article
from database.db_manager import add_article
import time
import random
from datetime import datetime
import pytz

BASE_URL = "https://vnexpress.net"
TIN_NONG_URL = "https://vnexpress.net/tin-nong"

def get_article_links(limit: int = None) -> list:
    """
    Láº¥y link bÃ i viáº¿t má»›i nháº¥t vá»›i chiáº¿n lÆ°á»£c linh hoáº¡t.
    """
    print(f"Äang táº£i danh sÃ¡ch bÃ i viáº¿t tá»«: {TIN_NONG_URL}")
    soup = fetch_soup(TIN_NONG_URL)
    if not soup:
        print("âŒ KhÃ´ng thá»ƒ táº£i trang danh sÃ¡ch bÃ i viáº¿t. Dá»«ng crawl.")
        return []
        
    links = []
    target_section = None
    
    # --- CHIáº¾N LÆ¯á»¢C Æ¯U TIÃŠN #1: TÃŒM KHá»I CÃ“ NGÃ€Y HÃ”M NAY ---
    tz_vietnam = pytz.timezone("Asia/Ho_Chi_Minh")
    today = datetime.now(tz_vietnam)
    today_href_str = f"{today.day}-{today.month}-{today.year}"
    print(f"ğŸ” [Æ¯u tiÃªn 1] Äang tÃ¬m khá»‘i bÃ i viáº¿t cÃ³ href chá»©a: '{today_href_str}'")

    all_sections = soup.select("div.list-news-subfolder")
    for section in all_sections:
        date_tag = section.select_one("h2.title-sub-folder a")
        if date_tag and date_tag.get('href') and today_href_str in date_tag.get('href'):
            print(f"âœ… [Æ¯u tiÃªn 1] TÃ¬m tháº¥y khá»‘i bÃ i viáº¿t cho ngÃ y hÃ´m nay.")
            target_section = section
            break
    
    # --- CHIáº¾N LÆ¯á»¢C Æ¯U TIÃŠN #2: Náº¾U KHÃ”NG CÃ“, Láº¤Y KHá»I Äáº¦U TIÃŠN ---
    if not target_section and all_sections:
        print(f"âš ï¸ [Æ¯u tiÃªn 2] KhÃ´ng tÃ¬m tháº¥y khá»‘i cá»§a ngÃ y hÃ´m nay. Láº¥y khá»‘i bÃ i viáº¿t Ä‘áº§u tiÃªn trÃªn trang.")
        target_section = all_sections[0]

    # --- TRÃCH XUáº¤T LINK Tá»ª KHá»I ÄÃƒ CHá»ŒN ---
    if target_section:
        for tag in target_section.select("h3.title-news a[href]"):
            href = tag.get("href")
            if href and (href.startswith("https://vnexpress.net") or href.startswith("/")):
                links.append(urljoin(BASE_URL, href))
    else:
        # --- CHIáº¾N LÆ¯á»¢C Æ¯U TIÃŠN #3: Náº¾U VáºªN KHÃ”NG CÃ“, Láº¤Y Táº¤T Cáº¢ LINK ---
        print(f"âš ï¸ [Æ¯u tiÃªn 3] KhÃ´ng tÃ¬m tháº¥y báº¥t ká»³ khá»‘i 'list-news-subfolder' nÃ o. Láº¥y táº¥t cáº£ cÃ¡c link trÃªn trang.")
        for tag in soup.select("h3.title-news a[href]"):
             href = tag.get("href")
             if href and (href.startswith("https://vnexpress.net") or href.startswith("/")):
                links.append(urljoin(BASE_URL, href))

    if not links:
        print("âŒ KhÃ´ng thá»ƒ tÃ¬m tháº¥y báº¥t ká»³ link bÃ i viáº¿t nÃ o báº±ng má»i chiáº¿n lÆ°á»£c.")
        return []

    # Loáº¡i trÃ¹ng láº·p vÃ  giá»¯ nguyÃªn thá»© tá»±
    seen = set()
    unique_links = [x for x in links if not (x in seen or seen.add(x))]

    if limit is not None:
        return unique_links[:limit]

    return unique_links

def crawl_latest_articles(limit: int = None) -> int:
    print("ğŸš€ Báº¯t Ä‘áº§u quÃ¡ trÃ¬nh crawl...")
    urls = get_article_links(limit=limit)
    print(f"ğŸ”— TÃ¬m tháº¥y tá»•ng cá»™ng {len(urls)} bÃ i viáº¿t Ä‘á»ƒ xá»­ lÃ½.")

    if not urls:
        print("--- KhÃ´ng cÃ³ bÃ i viáº¿t nÃ o Ä‘á»ƒ xá»­ lÃ½. Dá»«ng láº¡i. ---")
        return 0

    new_count = 0
    for idx, url in enumerate(urls, start=1):
        print(f"\nğŸ‘‰ Äang xá»­ lÃ½ bÃ i viáº¿t ({idx}/{len(urls)}): {url}")
        article = parse_article(url)
        
        if not article:
            print("âŒ Lá»—i parse, bá» qua bÃ i viáº¿t nÃ y.")
            time.sleep(1)
            continue

        thumb = article.get('image_url') or 'KhÃ´ng cÃ³'
        print(f"ğŸï¸ áº¢nh thumbnail: {thumb}")

        if add_article(article):
            print(f"âœ… ÄÃ£ lÆ°u bÃ i viáº¿t má»›i: {article['title']}")
            new_count += 1
        else:
            print(f"â© BÃ i viáº¿t Ä‘Ã£ tá»“n táº¡i, bá» qua.")

        sleep_time = random.uniform(1, 3)
        print(f"--- Táº¡m nghá»‰ {sleep_time:.2f} giÃ¢y Ä‘á»ƒ trÃ¡nh bá»‹ phÃ¡t hiá»‡n ---")
        time.sleep(sleep_time)

    print(f"\nğŸ‰ HoÃ n táº¥t! Tá»•ng sá»‘ bÃ i viáº¿t má»›i Ä‘Æ°á»£c lÆ°u: {new_count}")
    return new_count
